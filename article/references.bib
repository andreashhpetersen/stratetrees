@inproceedings{Andre2013,
  title = {Merge and Conquer: {{State}} Merging in Parametric Timed Automata},
  author = {Andr{\'e}, {\'E}tienne and Fribourg, Laurent and Soulat, Romain},
  year = {2013},
  month = oct,
  volume = {8172},
  pages = {381--396},
  doi = {10.1007/978-3-319-02444-8_27},
  isbn = {978-3-319-02443-1}
}

@misc{brorholtShieldedReinforcementLearning2023,
  title = {Shielded {{Reinforcement Learning}} for {{Hybrid Systems}}},
  author = {Brorholt, Asger Horn and Jensen, Peter Gj{\o}l and Larsen, Kim Guldstrand and Lorber, Florian and Schilling, Christian},
  year = {2023},
  month = aug,
  number = {arXiv:2308.14424},
  eprint = {2308.14424},
  primaryclass = {cs, eess},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2308.14424},
  urldate = {2023-09-20},
  abstract = {Safe and optimal controller synthesis for switched-controlled hybrid systems, which combine differential equations and discrete changes of the system's state, is known to be intricately hard. Reinforcement learning has been leveraged to construct near-optimal controllers, but their behavior is not guaranteed to be safe, even when it is encouraged by reward engineering. One way of imposing safety to a learned controller is to use a shield, which is correct by design. However, obtaining a shield for non-linear and hybrid environments is itself intractable. In this paper, we propose the construction of a shield using the so-called barbaric method, where an approximate finite representation of an underlying partition-based two-player safety game is extracted via systematically picked samples of the true transition function. While hard safety guarantees are out of reach, we experimentally demonstrate strong statistical safety guarantees with a prototype implementation and UPPAAL STRATEGO. Furthermore, we study the impact of the synthesized shield when applied as either a pre-shield (applied before learning a controller) or a post-shield (only applied after learning a controller). We experimentally demonstrate superiority of the pre-shielding approach. We apply our technique on a range of case studies, including two industrial examples, and further study post-optimization of the post-shielding approach.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Logic in Computer Science,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Systems and Control},
  file = {/home/andreashhp/Zotero/storage/ZQX8WBFW/brorholtShieldedReinforcementLearning2023 - Preprint - Shielded Reinforcement Learning for Hybrid Systems.pdf;/home/andreashhp/Zotero/storage/RZG75ZGG/2308.html}
}

@inproceedings{David2015UppaalS,
  title = {Uppaal Stratego},
  booktitle = {{{TACAS}}},
  author = {David, Alexandre and Jensen, Peter Gj{\o}l and Larsen, Kim G. and Mikucionis, Marius and Taankvist, Jakob Haahr},
  year = {2015}
}

@inproceedings{dtControl,
  title = {{{DtControl}}: {{Decision}} Tree Learning Algorithms for Controller Representation},
  booktitle = {Proceedings of the 23rd International Conference on Hybrid Systems: {{Computation}} and Control},
  author = {Ashok, Pranav and Jackermeier, Mathias and Jagtap, Pushpak and K{\v r}et{\'i}nsk{\'y}, Jan and Weininger, Maximilian and Zamani, Majid},
  year = {2020},
  series = {{{HSCC}} '20},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3365365.3383468},
  abstract = {Decision tree learning is a popular classification technique most commonly used in machine learning applications. Recent work has shown that decision trees can be used to represent provably-correct controllers concisely. Compared to representations using lookup tables or binary decision diagrams, decision tree representations are smaller and more explainable. We present dtControl, an easily extensible tool offering a wide variety of algorithms for representing memoryless controllers as decision trees. We highlight that the trees produced by dtControl are often very concise with a single-digit number of decision nodes. This demo is based on our tool paper [1].},
  articleno = {30},
  isbn = {978-1-4503-7018-9},
  keywords = {controller representation,decision tree,explainability,machine learning,non-uniform quantizer,symbolic control}
}

@inproceedings{dtControl2,
  title = {{{dtControl}} 2.0: {{Explainable}} Strategy Representation via Decision Tree Learning Steered by Experts},
  booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
  author = {Ashok, Pranav and Jackermeier, Mathias and K{\v r}et{\'i}nsk{\'y}, Jan and Weinhuber, Christoph and Weininger, Maximilian and Yadav, Mayank},
  editor = {Groote, Jan Friso and Larsen, Kim Guldstrand},
  year = {2021},
  pages = {326--345},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  abstract = {Recent advances have shown how decision trees are apt data structures for concisely representing strategies (or controllers) satisfying various objectives. Moreover, they also make the strategy more explainable. The recent tool dtControl had provided pipelines with tools supporting strategy synthesis for hybrid systems, such as SCOTS and Uppaal Stratego. We present dtControl 2.0, a new version with several fundamentally novel features. Most importantly, the user can now provide domain knowledge to be exploited in the decision tree learning process and can also interactively steer the process based on the dynamically provided information. To this end, we also provide a graphical user interface. It allows for inspection and re-computation of parts of the result, suggesting as well as receiving advice on predicates, and visual simulation of the decision-making process. Besides, we interface model checkers of probabilistic systems, namely STORM and PRISM and provide dedicated support for categorical enumeration-type state variables. Consequently, the controllers are more explainable and smaller.},
  isbn = {978-3-030-72013-1}
}

@article{m.t.l.b.IntroductionProbabilityTheory1951,
  title = {An {{Introduction}} to {{Probability Theory}} and Its {{Applications}}, Vol. {{I}}. {{By William Feller}}. [{{Pp}}. Xii + 419. {{New York}}: {{John Wiley}} and {{Sons Inc}}.; {{London}}: {{Chapman}} and {{Hall Ltd}}. 1950. {{Price}} 48s.]},
  shorttitle = {An {{Introduction}} to {{Probability Theory}} and Its {{Applications}}, Vol. {{I}}. {{By William Feller}}. [{{Pp}}. Xii + 419. {{New York}}},
  author = {{M.T.L.B.}},
  year = {1951},
  month = nov,
  journal = {Journal of the Staple Inn Actuarial Society},
  volume = {10},
  number = {04},
  pages = {316--318},
  issn = {0020-269X, 0020-269X},
  doi = {10.1017/S0020269X00004679},
  urldate = {2022-12-05},
  langid = {english}
}

@inproceedings{Manfred2019,
  title = {Teaching Stratego to Play Ball: {{Optimal}} Synthesis for Continuous Space {{MDPs}}},
  booktitle = {Automated Technology for Verification and Analysis},
  author = {Jaeger, Manfred and Jensen, Peter Gj{\o}l and Guldstrand Larsen, Kim and Legay, Axel and Sedwards, Sean and Taankvist, Jakob Haahr},
  editor = {Chen, Yu-Fang and Cheng, Chih-Hong and Esparza, Javier},
  year = {2019},
  pages = {81--97},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  abstract = {Formal models of cyber-physical systems, such as priced timed Markov decision processes, require a state space with continuous and discrete components. The problem of controller synthesis for such systems then can be cast as finding optimal strategies for Markov decision processes over a Euclidean state space. We develop two different reinforcement learning strategies that tackle the problem of continuous state spaces via online partition refinement techniques. We provide theoretical insights into the convergence of partition refinement schemes. Our techniques are implemented in . Experimental results show the advantages of our new techniques over previous optimization algorithms of .},
  isbn = {978-3-030-31784-3}
}

@book{Sutton1998,
  title = {Reinforcement Learning: {{An}} Introduction},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  year = {2018},
  edition = {2},
  publisher = {{The MIT Press}},
  added-at = {2019-07-13T10:11:53.000+0200},
  biburl = {https://www.bibsonomy.org/bibtex/2f46601cf8b13d39d1378af0d79438b12/lanteunis},
  interhash = {ac6b144aaec1819919a2fba9f705c852},
  intrahash = {f46601cf8b13d39d1378af0d79438b12},
  timestamp = {2019-07-13T10:11:53.000+0200}
}

@misc{towersGymnasium2023,
  title = {Gymnasium},
  author = {Towers, Mark and Terry, Jordan K. and Kwiatkowski, Ariel and Balis, John U. and de Cola, Gianluca and Deleu, Tristan and Goul{\~a}o, Manuel and Kallinteris, Andreas and KG, Arjun and Krimmel, Markus and {Perez-Vicente}, Rodrigo and Pierr{\'e}, Andrea and Schulhoff, Sander and Tai, Jun Jet and Shen, Andrew Tan Jin and Younis, Omar G.},
  year = {2023},
  month = mar,
  publisher = {{Zenodo}},
  doi = {10.5281/zenodo.8127026},
  urldate = {2023-07-08},
  abstract = {An API standard for single-agent reinforcement learning environments, with popular reference environments and related utilities (formerly Gym)}
}
