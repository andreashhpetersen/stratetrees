@article{ashokDtControlDecisionTree2020a,
  title = {{{dtControl}}: {{Decision}} Tree Learning Algorithms for Controller Representation},
  author = {Ashok, Pranav and Jackermeier, Mathias and Jagtap, Pushpak and Kret{\'i}nsk{\'y}, Jan and Weininger, Maximilian and Zamani, Majid},
  year = {2020},
  journal = {CoRR},
  volume = {abs/2002.04991},
  eprint = {2002.04991},
  archiveprefix = {arxiv},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/journals/corr/abs-2002-04991.bib},
  timestamp = {Tue, 20 Dec 2022 14:49:46 +0100}
}

@article{bellmanAdaptiveControlProcesses1959,
  title = {On Adaptive Control Processes},
  author = {Bellman, R. and Kalaba, R.},
  year = {1959},
  month = nov,
  journal = {IRE Transactions on Automatic Control},
  volume = {4},
  number = {2},
  pages = {1--9},
  issn = {1558-3651},
  doi = {10.1109/TAC.1959.1104847},
  abstract = {One of the most challenging areas in the field of automatic control is the design of automatic control devices that 'learn' to improve their performamce based upon experience, i.e., that can adapt themselves to circumstances as they find them. The military and commercial implications of such devices are impressive, and interest in the two main areas of research in the field of control, the USA and the USSR, runs high. Unfortunately, though, both theory and construction of adaptive controllers are in their infancy, and some time may pass before they are commonplace. Nonetheless, development at this time of adequate theories of processes of this nature is essential. The purpose of our paper is to show how the functional equation technique of a new mathematical discipline, dynamic programming, can be used in the formulation and solution of a variety of optimization problems concerning the design of adaptive devices. Although, occasionally, a solution in closed form can be obtained, in general, numerical solution via the use of high-speed digital computers is contemplated. We discuss here the closely allied problems of formulating adaptive control processes in precise mathematical terms and of presenting feasible computational algoritbms for determining numerical solutioms. To illustrate the general concepts, consider a system which is governed by the inhomogeneous Van der Pol equation\textbackslash ddotx + \textbackslash mu(x\^2 - 1) \textbackslash dotx + x = r(t), 0 \textbackslash leq t \textbackslash leq T, wherer(t)is a random function whose statistical properties are only partially known to a feedback control device which seeks to keep the system near the unstable equilibrium statex = 0, \textbackslash dotx = 0. It proposes to do this by selecting the value of {$\mu$} as a function of the state of the system at timet, and the timetitself. By observing the random processr(t), the controller may, with the passage of time, infer more and more concerning the statistical properties of the functionr(t)and thus may be expected to improve the quality of its control decisions. In this way the controller adapts itself to circumstances as it finds them. The process is thus an interesting example of adaptive control, and, conceivably, with some immediate applications. Lastly, some areas of this general domain requiring additional research are indicated.},
  keywords = {Adaptive control,Concrete,Control systems,Differential equations,Dynamic programming,Force control,Nonlinear equations,Optimal control,Process control,Random variables},
  file = {/home/andreashhp/Zotero/storage/PLV26BEH/bellmanAdaptiveControlProcesses1959 - Journal Article - On adaptive control processes.pdf;/home/andreashhp/Zotero/storage/DDZ8XAJ2/1104847.html}
}

@misc{brorholtShieldedReinforcementLearning2023,
  title = {Shielded {{Reinforcement Learning}} for {{Hybrid Systems}}},
  author = {Brorholt, Asger Horn and Jensen, Peter Gj{\o}l and Larsen, Kim Guldstrand and Lorber, Florian and Schilling, Christian},
  year = {2023},
  month = aug,
  number = {arXiv:2308.14424},
  eprint = {2308.14424},
  primaryclass = {cs, eess},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2308.14424},
  urldate = {2023-09-20},
  abstract = {Safe and optimal controller synthesis for switched-controlled hybrid systems, which combine differential equations and discrete changes of the system's state, is known to be intricately hard. Reinforcement learning has been leveraged to construct near-optimal controllers, but their behavior is not guaranteed to be safe, even when it is encouraged by reward engineering. One way of imposing safety to a learned controller is to use a shield, which is correct by design. However, obtaining a shield for non-linear and hybrid environments is itself intractable. In this paper, we propose the construction of a shield using the so-called barbaric method, where an approximate finite representation of an underlying partition-based two-player safety game is extracted via systematically picked samples of the true transition function. While hard safety guarantees are out of reach, we experimentally demonstrate strong statistical safety guarantees with a prototype implementation and UPPAAL STRATEGO. Furthermore, we study the impact of the synthesized shield when applied as either a pre-shield (applied before learning a controller) or a post-shield (only applied after learning a controller). We experimentally demonstrate superiority of the pre-shielding approach. We apply our technique on a range of case studies, including two industrial examples, and further study post-optimization of the post-shielding approach.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Logic in Computer Science,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Systems and Control},
  file = {/home/andreashhp/Zotero/storage/ZQX8WBFW/brorholtShieldedReinforcementLearning2023 - Preprint - Shielded Reinforcement Learning for Hybrid Systems.pdf;/home/andreashhp/Zotero/storage/RZG75ZGG/2308.html}
}

@incollection{davidUppaalStratego2015,
  title = {Uppaal {{Stratego}}},
  booktitle = {Tools and {{Algorithms}} for the {{Construction}} and {{Analysis}} of {{Systems}}},
  author = {David, Alexandre and Jensen, Peter Gj{\o}l and Larsen, Kim Guldstrand and Miku{\v c}ionis, Marius and Taankvist, Jakob Haahr},
  editor = {Baier, Christel and Tinelli, Cesare},
  year = {2015},
  volume = {9035},
  pages = {206--211},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-662-46681-0_16},
  urldate = {2022-11-21},
  abstract = {Uppaal Stratego is a novel tool which facilitates generation, optimization, comparison as well as consequence and performance exploration of strategies for stochastic priced timed games in a user-friendly manner. The tool allows for efficient and flexible ``strategy-space'' exploration before adaptation in a final implementation by maintaining strategies as first class objects in the model-checking query language. The paper describes the strategies and their properties, construction and transformation algorithms and a typical tool usage scenario.},
  isbn = {978-3-662-46680-3 978-3-662-46681-0},
  langid = {english},
  file = {/home/andreashhp/Zotero/storage/PKZK6KEX/David et al. - 2015 - Uppaal Stratego.pdf}
}

@article{hyafilConstructingOptimalBinary1976,
  title = {Constructing Optimal Binary Decision Trees Is {{NP-complete}}},
  author = {Hyafil, Laurent and Rivest, Ronald L.},
  year = {1976},
  journal = {Information Processing Letters},
  volume = {5},
  number = {1},
  pages = {15--17},
  issn = {0020-0190},
  doi = {10.1016/0020-0190(76)90095-8},
  keywords = {Binary decision trees,computational complexity,NP-complete},
  file = {/home/andreashhp/Zotero/storage/KZA4S6UU/HYAFIL197615 - Journal Article - Constructing optimal binary decision trees is NP-complete.pdf}
}

@incollection{jaegerTeachingStrategoPlay2019,
  title = {Teaching {{Stratego}} to {{Play Ball}}: {{Optimal Synthesis}} for {{Continuous Space MDPs}}},
  shorttitle = {Teaching {{Stratego}} to {{Play Ball}}},
  booktitle = {Automated {{Technology}} for {{Verification}} and {{Analysis}}},
  author = {Jaeger, Manfred and Jensen, Peter Gj{\o}l and Guldstrand Larsen, Kim and Legay, Axel and Sedwards, Sean and Taankvist, Jakob Haahr},
  editor = {Chen, Yu-Fang and Cheng, Chih-Hong and Esparza, Javier},
  year = {2019},
  volume = {11781},
  pages = {81--97},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-31784-3_5},
  urldate = {2022-11-18},
  abstract = {Formal models of cyber-physical systems, such as priced timed Markov decision processes, require a state space with continuous and discrete components. The problem of controller synthesis for such systems then can be cast as finding optimal strategies for Markov decision processes over a Euclidean state space. We develop two different reinforcement learning strategies that tackle the problem of continuous state spaces via online partition refinement techniques. We provide theoretical insights into the convergence of partition refinement schemes. Our techniques are implemented in Uppaal Stratego. Experimental results show the advantages of our new techniques over previous optimization algorithms of Uppaal Stratego.},
  isbn = {978-3-030-31783-6 978-3-030-31784-3},
  langid = {english},
  file = {/home/andreashhp/Zotero/storage/IE329LL8/Jaeger et al. - 2019 - Teaching Stratego to Play Ball Optimal Synthesis .pdf}
}
